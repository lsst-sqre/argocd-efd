{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore shard data to an existing database "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `influxd restore` command cannot restore data to an existing database. The recommended restore procedure is to restore incremental backups (or a shard) to a temporaty database and use an InfluxQL query to copy data from one database to another. \n",
    "\n",
    "The recommended query usually take a long time to run, depending on the size of the database to copy, and sometimes it fails with the [ERR: partial write: field type conflict](https://community.influxdata.com/t/help-with-err-partial-write-field-type-conflict-error/25531) error.\n",
    "\n",
    "This notebook outlines a procedure using the `aioinflux` async Python client to copy data from one database to another to get around of the problems above. This procedure runs one async query per measurement and is much faster than the single query approach. For a database with ~1000 measurements we have observed data rates a thousand times faster. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InfluxDB instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this notebook on the same cluster where InfluxDB runs. We connect to the InfluxDB internal cluster address to bypass  the ingress, otherwhise the connection is killed after 60s given our current cluster configuration. This avoids the `ClientPayloadError: Response payload is not completed` error.\n",
    "\n",
    "The InfluxDB instance also needs to be configure with `max-concurrent-queries = 0` and `query-timeout = \"0s\"` to avoid queries being killed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"sasquatch-influxdb.sasquatch\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for the InfluxDB admin credentials in the SQuaRE 1Password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "username = \"admin\"\n",
    "password = getpass.getpass(prompt='Password for user `{}`: '.format(username))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source database and retention policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_db = \"<source db with the incremental retore data>\"\n",
    "src_rp = \"<source db retention policy name>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the aioinflux client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aioinflux import InfluxDBClient\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default aiohttp client timeout is only 300s, if you have queries that run longer thant that you also neeed to set a different timeout here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InfluxDBClient(host=HOST, port='8086', path='/', db=src_db, username=username, password=password, timeout=86400, output='dataframe')\n",
    "client.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the list of measurements from the source database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = await client.show_measurements()\n",
    "measurements.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy measurements to the destination database\n",
    "Using a test database so we can verify that both databases have the same number of points for each measurement to validate this procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_db = \"<destination db to where you want to restore the data>\"\n",
    "dest_rp = \"<destination db retention policy name>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `GROUP BY *` is required to preserve tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def copy(measurement): \n",
    "    q = f'''SELECT * INTO \"{dest_db}\".\"{dest_rp}\".\"{measurement}\" FROM \"{src_db}\".\"{src_rp}\".\"{measurement}\" GROUP BY * '''\n",
    "    result = await client.query(q)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a large number of measurements to copy over. Batch size can be used to control the number of async queries executed in each iteration, it gives some control on the InfluxDB load. The time to process each batch is given by the slowest query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = []\n",
    "BATCH_SIZE = 300\n",
    "for count, measurement in enumerate(measurements['name']):\n",
    "    batch.append(measurement)\n",
    "    if count % BATCH_SIZE == 0:       \n",
    "        coroutines = [copy(m) for m in batch]\n",
    "        await asyncio.gather(*coroutines)\n",
    "        print(\"Processing a new batch...\")\n",
    "        batch = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify copy \n",
    "To validade this procedure we restored one shard to an empty database and compared the number of points on each measurement between the source and destination databases. Need a better test if the copy is done to an existing database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for measurement in measurements['name']:\n",
    "    src_count = await client.query(f'''SELECT COUNT(*) FROM \"{src_db}\".\"{src_rp}\".\"{measurement}\"  ''') \n",
    "    dest_count = await client.query(f'''SELECT COUNT(*) FROM \"{dest_db}\".\"{dest_rp}\".\"{measurement}\"  ''') \n",
    "    assert dest_count.equals(src_count)\n",
    "                               "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
